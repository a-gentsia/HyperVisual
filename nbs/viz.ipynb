{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# import pandas as pd\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorSpaceAnalyzer:\n",
    "    def __init__(self, api_key, index_name):  #environment, \n",
    "        self.api_key = api_key\n",
    "        # self.environment = environment\n",
    "        self.index_name = index_name\n",
    "        self.pinecone = self.initialize_pinecone()\n",
    "        self.index = self.pinecone.Index(self.index_name)\n",
    "        self.all_vectors = None\n",
    "\n",
    "    def initialize_pinecone(self):\n",
    "        pinecone = Pinecone(api_key=self.api_key)\n",
    "        index = pinecone.Index(self.index_name)\n",
    "        # pinecone.init(api_key=self.api_key, environment=self.environment)\n",
    "        return pinecone\n",
    "\n",
    "    def fetch_vectors(self, batch_size=1000):\n",
    "        if self.all_vectors is None:\n",
    "            index_info = self.index.describe_index_stats()\n",
    "            \n",
    "            # Try different possible keys for total vector count\n",
    "            total_vector_count = None\n",
    "            for key in ['total_vector_count', 'totalVectorCount', 'vector_count']:\n",
    "                if key in index_info:\n",
    "                    total_vector_count = index_info[key]\n",
    "                    break\n",
    "            \n",
    "            # If not found in top level, check in namespaces\n",
    "            if total_vector_count is None and 'namespaces' in index_info:\n",
    "                default_namespace = index_info['namespaces'].get('', {})\n",
    "                for key in ['vector_count', 'vectorCount']:\n",
    "                    if key in default_namespace:\n",
    "                        total_vector_count = default_namespace[key]\n",
    "                        break\n",
    "            \n",
    "            if total_vector_count is None:\n",
    "                raise ValueError(\"Unable to determine total vector count from index stats\")\n",
    "\n",
    "            print(f\"Total vector count: {total_vector_count}\")\n",
    "####\n",
    "            # # pinecone = Pinecone(api_key=self.api_key)\n",
    "            # # index = pinecone.Index(self.index_name)            \n",
    "            # index_info = self.index.describe_index_stats()\n",
    "            # print(index_info)\n",
    "            # total_vector_count = index_info[\"totalVectorCount\"]\n",
    "            # # total_vector_count = index_info.get(\"totalVectorCount\")\n",
    "            # print(int(total_vector_count))\n",
    "####\n",
    "\n",
    "\n",
    "\n",
    "            vectors = []\n",
    "            for i in range(0, int(total_vector_count), batch_size):\n",
    "                ids = [str(j) for j in range(i, min(i+batch_size, total_vector_count))]\n",
    "                response = self.index.fetch(ids)\n",
    "                batch_vectors = [v['values'] for v in response['vectors'].values()]\n",
    "                vectors.extend(batch_vectors)\n",
    "            print(f\"Fetched {len(vectors)} vectors.\")\n",
    "            self.all_vectors = np.array(vectors) #.reshape(-1, 1)\n",
    "            print(f\"Shape of all_vectors: {self.all_vectors.shape}\")\n",
    "        \n",
    "        if self.all_vectors is None or len(self.all_vectors) == 0:\n",
    "            raise ValueError(\"No vectors were fetched from the index.\")\n",
    "    \n",
    "        if self.all_vectors.ndim == 1:\n",
    "            self.all_vectors = self.all_vectors.reshape(1, -1)\n",
    "        \n",
    "        return self.all_vectors\n",
    "\n",
    "    def find_optimal_clusters(self, max_clusters=20):\n",
    "        vectors = self.fetch_vectors()\n",
    "\n",
    "        \n",
    "        if len(vectors) < 2:\n",
    "            print(\"Not enough vectors to perform clustering.\")\n",
    "            return 1\n",
    "    \n",
    "        max_clusters = min(max_clusters, len(vectors) - 1)\n",
    "        \n",
    "        \n",
    "        sse = []\n",
    "\n",
    "        for k in range(1, max_clusters + 1):\n",
    "            kmeans = KMeans(n_clusters=k, random_state=2024, n_init=10)\n",
    "            kmeans.fit(vectors)\n",
    "            sse.append(kmeans.inertia_)\n",
    "        \n",
    "        if len(sse) < 3:\n",
    "            print(\"Not enough data points to determine optimal clusters. Using 1 cluster.\")\n",
    "            return 1\n",
    "\n",
    "        # Determine the \"elbow\" point\n",
    "        elbows = np.diff(sse, 2)\n",
    "        optimal_clusters = np.argmax(elbows) + 2\n",
    "\n",
    "        return optimal_clusters\n",
    "\n",
    "    def analyze_vector_space(self):\n",
    "        vectors = self.fetch_vectors()\n",
    "        if len(vectors) < 2:\n",
    "            print(\"Not enough vectors to perform analysis.\")\n",
    "            return None\n",
    "        optimal_clusters = self.find_optimal_clusters()\n",
    "        print(f\"Optimal number of clusters: {optimal_clusters}\")\n",
    "\n",
    "        # Perform K-means clustering\n",
    "        kmeans = KMeans(n_clusters=optimal_clusters, random_state=2024, n_init=10)\n",
    "        cluster_labels = kmeans.fit_predict(vectors)\n",
    "\n",
    "        # Perform PCA for visualization\n",
    "        pca = PCA(n_components=2)\n",
    "        vectors_2d = pca.fit_transform(vectors)\n",
    "\n",
    "        # Visualize the clusters\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        scatter = plt.scatter(vectors_2d[:, 0], vectors_2d[:, 1], c=cluster_labels, cmap='viridis')\n",
    "        plt.colorbar(scatter)\n",
    "        plt.title('PCA visualization of vector clusters')\n",
    "        plt.xlabel('First Principal Component')\n",
    "        plt.ylabel('Second Principal Component')\n",
    "        plt.savefig('vector_clusters.png')\n",
    "        plt.close()\n",
    "\n",
    "        # Find centroids in original space\n",
    "        centroids = kmeans.cluster_centers_\n",
    "\n",
    "        # Function to find nearest vector to a given point\n",
    "        def find_nearest_vector(point, vectors):\n",
    "            distances = np.linalg.norm(vectors - point, axis=1)\n",
    "            return np.argmin(distances)\n",
    "\n",
    "        # Find nearest actual vectors to centroids\n",
    "        nearest_to_centroids = [find_nearest_vector(centroid, vectors) for centroid in centroids]\n",
    "\n",
    "        # Find outliers (e.g., points far from their cluster center)\n",
    "        distances_to_centroid = np.min(kmeans.transform(vectors), axis=1)\n",
    "        outlier_threshold = np.percentile(distances_to_centroid, 95)  # Top 5% as outliers\n",
    "        outlier_indices = np.where(distances_to_centroid > outlier_threshold)[0]\n",
    "\n",
    "        return {\n",
    "            \"cluster_labels\": cluster_labels,\n",
    "            \"centroids\": centroids,\n",
    "            \"nearest_to_centroids\": nearest_to_centroids,\n",
    "            \"outlier_indices\": outlier_indices\n",
    "        }\n",
    "\n",
    "    def generate_sample_queries(self, analysis_results, num_samples=5):\n",
    "        cluster_labels, centroids, nearest_to_centroids, outlier_indices = (\n",
    "            analysis_results[\"cluster_labels\"],\n",
    "            analysis_results[\"centroids\"],\n",
    "            analysis_results[\"nearest_to_centroids\"],\n",
    "            analysis_results[\"outlier_indices\"]\n",
    "        )\n",
    "\n",
    "        # Generate sample queries for centroids\n",
    "        centroid_queries = []\n",
    "        for i, nearest_idx in enumerate(nearest_to_centroids):\n",
    "            cluster_id = cluster_labels[nearest_idx]\n",
    "            query = f\"This is a sample query for the vectors in cluster {cluster_id}.\"\n",
    "            centroid_queries.append(query)\n",
    "\n",
    "        # Generate sample queries for outliers\n",
    "        outlier_queries = []\n",
    "        for i, outlier_idx in enumerate(outlier_indices[:num_samples]):\n",
    "            query = f\"This is a sample query for an outlier vector.\"\n",
    "            outlier_queries.append(query)\n",
    "\n",
    "        return {\n",
    "            \"centroid_queries\": centroid_queries,\n",
    "            \"outlier_queries\": outlier_queries\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vector count: 29754\n",
      "Fetched 0 vectors.\n",
      "Shape of all_vectors: (0,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No vectors were fetched from the index.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# api_key = \"YOUR_API_KEY\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# environment = \"YOUR_ENVIRONMENT\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# index_name = \"YOUR_INDEX_NAME\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m VectorSpaceAnalyzer(PINECONE_API_KEY, PINECONE_INDEX) \u001b[38;5;66;03m#environment,\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m analysis_results \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_vector_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m sample_queries \u001b[38;5;241m=\u001b[39m analyzer\u001b[38;5;241m.\u001b[39mgenerate_sample_queries(analysis_results)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCentroid sample queries:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[35], line 98\u001b[0m, in \u001b[0;36mVectorSpaceAnalyzer.analyze_vector_space\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_vector_space\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 98\u001b[0m     vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(vectors) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough vectors to perform analysis.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[35], line 62\u001b[0m, in \u001b[0;36mVectorSpaceAnalyzer.fetch_vectors\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of all_vectors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_vectors\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_vectors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_vectors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo vectors were fetched from the index.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_vectors\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_vectors\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: No vectors were fetched from the index."
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_INDEX = os.getenv(\"PINECONE_INDEX\")\n",
    "# api_key = \"YOUR_API_KEY\"\n",
    "# environment = \"YOUR_ENVIRONMENT\"\n",
    "# index_name = \"YOUR_INDEX_NAME\"\n",
    "\n",
    "analyzer = VectorSpaceAnalyzer(PINECONE_API_KEY, PINECONE_INDEX) #environment,\n",
    "analysis_results = analyzer.analyze_vector_space()\n",
    "sample_queries = analyzer.generate_sample_queries(analysis_results)\n",
    "\n",
    "print(\"Centroid sample queries:\")\n",
    "for query in sample_queries[\"centroid_queries\"]:\n",
    "    print(query)\n",
    "\n",
    "print(\"\\nOutlier sample queries:\")\n",
    "for query in sample_queries[\"outlier_queries\"]:\n",
    "    print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
